#!/usr/bin/env python3
"""
é‡æ–°å¤„ç†ç°æœ‰è½¬å½•æ–‡ä»¶çš„è„šæœ¬
è·³è¿‡ä¸‹è½½å’Œè½¬å½•æ­¥éª¤ï¼Œç›´æ¥å¯¹ç°æœ‰è½¬å½•æ–‡ä»¶è¿›è¡Œä¿¡æ¯æå–
"""

import json
import logging
import sys
from pathlib import Path
from typing import Dict, List, Optional
import argparse

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from core.info_extractor import FinancialInfoExtractor

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class TranscriptionReprocessor:
    """è½¬å½•æ–‡ä»¶é‡æ–°å¤„ç†å™¨"""
    
    def __init__(self, base_dir: str = "downloads"):
        """
        åˆå§‹åŒ–é‡æ–°å¤„ç†å™¨
        
        Args:
            base_dir: ä¸‹è½½ç›®å½•çš„æ ¹è·¯å¾„
        """
        self.base_dir = Path(base_dir)
        self.extractor = FinancialInfoExtractor()
        
    def find_transcription_dirs(self) -> List[Path]:
        """
        æŸ¥æ‰¾æ‰€æœ‰åŒ…å«è½¬å½•æ–‡ä»¶çš„ç›®å½•
        
        Returns:
            åŒ…å«è½¬å½•æ–‡ä»¶çš„ç›®å½•åˆ—è¡¨
        """
        transcription_dirs = []
        
        # éå†æ‰€æœ‰å¯èƒ½çš„ç›®å½•ç»“æ„
        for item in self.base_dir.rglob("transcription"):
            if item.is_dir() and list(item.glob("*.txt")):
                transcription_dirs.append(item)
                
        logger.info(f"ğŸ“ æ‰¾åˆ° {len(transcription_dirs)} ä¸ªè½¬å½•ç›®å½•")
        for dir_path in transcription_dirs:
            txt_count = len(list(dir_path.glob("*.txt")))
            logger.info(f"  - {dir_path}: {txt_count} ä¸ªè½¬å½•æ–‡ä»¶")
            
        return transcription_dirs
        
    def process_transcription_dir(self, transcription_dir: Path, force_reprocess: bool = False) -> Dict[str, any]:
        """
        å¤„ç†å•ä¸ªè½¬å½•ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
        
        Args:
            transcription_dir: è½¬å½•æ–‡ä»¶ç›®å½•è·¯å¾„
            force_reprocess: æ˜¯å¦å¼ºåˆ¶é‡æ–°å¤„ç†å·²å­˜åœ¨çš„åˆ†ææ–‡ä»¶
            
        Returns:
            å¤„ç†ç»“æœç»Ÿè®¡
        """
        logger.info(f"ğŸ” å¤„ç†è½¬å½•ç›®å½•: {transcription_dir}")
        
        # è·å–å¯¹åº”çš„åˆ†æç›®å½•
        analysis_dir = transcription_dir.parent / "analysis"
        analysis_dir.mkdir(exist_ok=True)
        
        # è·å–æ‰€æœ‰è½¬å½•æ–‡ä»¶
        txt_files = list(transcription_dir.glob("*.txt"))
        logger.info(f"ğŸ“„ æ‰¾åˆ° {len(txt_files)} ä¸ªè½¬å½•æ–‡ä»¶")
        
        results = {
            "total": len(txt_files),
            "processed": 0,
            "skipped": 0,
            "failed": 0,
            "success": 0
        }
        
        for txt_file in txt_files:
            try:
                # æ£€æŸ¥å¯¹åº”çš„åˆ†ææ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
                analysis_file = analysis_dir / f"{txt_file.stem}_analysis.json"
                
                if analysis_file.exists() and not force_reprocess:
                    logger.info(f"â­ï¸  è·³è¿‡å·²å­˜åœ¨çš„åˆ†ææ–‡ä»¶: {analysis_file.name}")
                    results["skipped"] += 1
                    continue
                
                logger.info(f"ğŸ”„ å¤„ç†è½¬å½•æ–‡ä»¶: {txt_file.name}")
                
                # è¯»å–è½¬å½•å†…å®¹
                with open(txt_file, 'r', encoding='utf-8') as f:
                    transcription_text = f.read().strip()
                
                if not transcription_text:
                    logger.warning(f"âš ï¸  è½¬å½•æ–‡ä»¶ä¸ºç©º: {txt_file.name}")
                    results["failed"] += 1
                    continue
                
                # ä»æ–‡ä»¶åæå–è§†é¢‘æ ‡é¢˜ï¼ˆå¦‚æœå¯èƒ½ï¼‰
                video_title = self._extract_title_from_filename(txt_file.name)
                
                logger.info(f"ğŸ“ å¼€å§‹æå–ä¿¡æ¯ï¼Œè½¬å½•æ–‡æœ¬é•¿åº¦: {len(transcription_text)} å­—ç¬¦")
                
                # è°ƒç”¨ä¿¡æ¯æå–
                extracted_info = self.extractor.extract_key_info(
                    transcription_text=transcription_text,
                    video_title=video_title
                )
                
                # ä¿å­˜åˆ†æç»“æœ
                with open(analysis_file, 'w', encoding='utf-8') as f:
                    json.dump(extracted_info, f, ensure_ascii=False, indent=2)
                
                logger.info(f"âœ… æˆåŠŸä¿å­˜åˆ†æç»“æœ: {analysis_file.name}")
                logger.info(f"ğŸ“Š æå–æ–¹æ³•: {extracted_info.get('extraction_method', 'unknown')}")
                
                if "tokens_used" in extracted_info:
                    logger.info(f"ğŸ’° ä½¿ç”¨tokens: {extracted_info['tokens_used']}")
                    
                if "attempts_used" in extracted_info:
                    logger.info(f"ğŸ”„ é‡è¯•æ¬¡æ•°: {extracted_info['attempts_used']}")
                
                results["success"] += 1
                results["processed"] += 1
                
            except Exception as e:
                logger.error(f"âŒ å¤„ç†å¤±è´¥ {txt_file.name}: {e}")
                results["failed"] += 1
                results["processed"] += 1
                
        return results
    
    def _extract_title_from_filename(self, filename: str) -> str:
        """
        ä»æ–‡ä»¶åæå–å¯èƒ½çš„è§†é¢‘æ ‡é¢˜
        
        Args:
            filename: è½¬å½•æ–‡ä»¶å
            
        Returns:
            æå–çš„æ ‡é¢˜
        """
        # ç§»é™¤æ‰©å±•åå’Œå‰ç¼€
        base_name = filename.replace('.txt', '')
        if base_name.startswith('rhino_'):
            base_name = base_name[6:]  # ç§»é™¤ 'rhino_' å‰ç¼€
            
        # ä½¿ç”¨è§†é¢‘IDä½œä¸ºæ ‡é¢˜ï¼ˆå¦‚æœéœ€è¦æ›´æ™ºèƒ½çš„æ ‡é¢˜æå–ï¼Œå¯ä»¥åç»­æ”¹è¿›ï¼‰
        return f"Rhino Finance Video - {base_name}"
    
    def reprocess_all(self, force_reprocess: bool = False, target_dir: Optional[str] = None) -> None:
        """
        é‡æ–°å¤„ç†æ‰€æœ‰è½¬å½•æ–‡ä»¶
        
        Args:
            force_reprocess: æ˜¯å¦å¼ºåˆ¶é‡æ–°å¤„ç†å·²å­˜åœ¨çš„åˆ†ææ–‡ä»¶
            target_dir: æŒ‡å®šçš„ç›®æ ‡ç›®å½•ï¼Œå¦‚æœNoneåˆ™å¤„ç†æ‰€æœ‰å‘ç°çš„ç›®å½•
        """
        logger.info("ğŸš€ å¼€å§‹é‡æ–°å¤„ç†è½¬å½•æ–‡ä»¶...")
        
        if target_dir:
            # å¤„ç†æŒ‡å®šç›®å½•
            target_path = Path(target_dir)
            if not target_path.exists():
                logger.error(f"âŒ æŒ‡å®šç›®å½•ä¸å­˜åœ¨: {target_dir}")
                return
                
            if target_path.name == "transcription":
                dirs_to_process = [target_path]
            else:
                transcription_dir = target_path / "transcription"
                if transcription_dir.exists():
                    dirs_to_process = [transcription_dir]
                else:
                    logger.error(f"âŒ åœ¨æŒ‡å®šç›®å½•ä¸­æœªæ‰¾åˆ°transcriptionå­ç›®å½•: {target_dir}")
                    return
        else:
            # æŸ¥æ‰¾æ‰€æœ‰è½¬å½•ç›®å½•
            dirs_to_process = self.find_transcription_dirs()
        
        if not dirs_to_process:
            logger.warning("âš ï¸  æœªæ‰¾åˆ°ä»»ä½•è½¬å½•ç›®å½•")
            return
        
        total_stats = {
            "total": 0,
            "processed": 0,
            "skipped": 0,
            "failed": 0,
            "success": 0
        }
        
        # å¤„ç†æ¯ä¸ªç›®å½•
        for transcription_dir in dirs_to_process:
            try:
                stats = self.process_transcription_dir(transcription_dir, force_reprocess)
                
                # ç´¯è®¡ç»Ÿè®¡
                for key in total_stats:
                    total_stats[key] += stats[key]
                    
                logger.info(f"ğŸ“Š ç›®å½•å¤„ç†å®Œæˆ {transcription_dir}:")
                logger.info(f"   æ€»è®¡: {stats['total']}, æˆåŠŸ: {stats['success']}, "
                          f"è·³è¿‡: {stats['skipped']}, å¤±è´¥: {stats['failed']}")
                          
            except Exception as e:
                logger.error(f"âŒ å¤„ç†ç›®å½•å¤±è´¥ {transcription_dir}: {e}")
        
        # è¾“å‡ºæ€»ä½“ç»Ÿè®¡
        logger.info("ğŸ‰ å…¨éƒ¨å¤„ç†å®Œæˆ!")
        logger.info("ğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        logger.info(f"   æ€»è®¡æ–‡ä»¶: {total_stats['total']}")
        logger.info(f"   æˆåŠŸå¤„ç†: {total_stats['success']}")
        logger.info(f"   è·³è¿‡æ–‡ä»¶: {total_stats['skipped']}")
        logger.info(f"   å¤„ç†å¤±è´¥: {total_stats['failed']}")
        
        if total_stats['success'] > 0:
            success_rate = (total_stats['success'] / total_stats['processed']) * 100 if total_stats['processed'] > 0 else 0
            logger.info(f"   æˆåŠŸç‡: {success_rate:.1f}%")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="ğŸ”„ é‡æ–°å¤„ç†ç°æœ‰è½¬å½•æ–‡ä»¶ï¼Œè·³è¿‡ä¸‹è½½å’Œè½¬å½•æ­¥éª¤",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # å¤„ç†æ‰€æœ‰å‘ç°çš„è½¬å½•æ–‡ä»¶
  python tools/reprocess_transcriptions.py
  
  # å¼ºåˆ¶é‡æ–°å¤„ç†æ‰€æœ‰æ–‡ä»¶ï¼ˆåŒ…æ‹¬å·²å­˜åœ¨åˆ†æçš„æ–‡ä»¶ï¼‰
  python tools/reprocess_transcriptions.py --force
  
  # åªå¤„ç†æŒ‡å®šç›®å½•
  python tools/reprocess_transcriptions.py --dir downloads/rhino_finance/2025-09-10
  
  # æŒ‡å®šåŸºç¡€ä¸‹è½½ç›®å½•
  python tools/reprocess_transcriptions.py --base-dir /path/to/downloads
        """
    )
    
    parser.add_argument(
        '--force', '-f',
        action='store_true',
        help='å¼ºåˆ¶é‡æ–°å¤„ç†å·²å­˜åœ¨åˆ†ææ–‡ä»¶çš„è½¬å½•'
    )
    
    parser.add_argument(
        '--dir', '-d',
        type=str,
        help='æŒ‡å®šè¦å¤„ç†çš„ç›®å½•è·¯å¾„ï¼ˆå¯ä»¥æ˜¯åŒ…å«transcriptionçš„çˆ¶ç›®å½•ï¼‰'
    )
    
    parser.add_argument(
        '--base-dir', '-b',
        type=str,
        default='downloads',
        help='åŸºç¡€ä¸‹è½½ç›®å½•è·¯å¾„ (é»˜è®¤: downloads)'
    )
    
    args = parser.parse_args()
    
    try:
        # åˆ›å»ºé‡æ–°å¤„ç†å™¨
        reprocessor = TranscriptionReprocessor(base_dir=args.base_dir)
        
        # å¼€å§‹å¤„ç†
        reprocessor.reprocess_all(
            force_reprocess=args.force,
            target_dir=args.dir
        )
        
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ ç”¨æˆ·ä¸­æ–­å¤„ç†")
    except Exception as e:
        logger.error(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
