"""
è´¢ç»ä¿¡æ¯æå–å™¨
ä»ASRè½¬å½•çš„æ–‡æœ¬ä¸­æå–å…³é”®æŠ•èµ„ä¿¡æ¯ï¼ŒåŒ…æ‹¬å®è§‚æ•°æ®ã€ä¸ªè‚¡åˆ†æã€å…³é”®ç‚¹ä½ç­‰
"""

import sys
import json
import logging
from typing import Dict, Any, Optional, List
from pathlib import Path

project_root = Path(__file__).parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# å°è¯•å¯¼å…¥gemini_llm
try:
    from core.gemini_llm import GeminiLLM, gemini_config
    GEMINI_AVAILABLE = True
except ImportError as e:
    GEMINI_AVAILABLE = False
    logger.warning(f"Gemini LLMä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ä¾èµ–å’Œé…ç½®: {e}")


class FinancialInfoExtractor:
    """è´¢ç»ä¿¡æ¯æå–å™¨ç±»"""
    
    def __init__(self, use_gemini: bool = True):
        """
        åˆå§‹åŒ–ä¿¡æ¯æå–å™¨
        
        Args:
            use_gemini: æ˜¯å¦ä½¿ç”¨Gemini LLMè¿›è¡Œæå–
        """
        logger.info(f"ğŸ”§ åˆå§‹åŒ–ä¿¡æ¯æå–å™¨, use_gemini={use_gemini}, GEMINI_AVAILABLE={GEMINI_AVAILABLE}")
        
        self.use_gemini = use_gemini and GEMINI_AVAILABLE
        
        # å®šä¹‰è´¢ç»ä¿¡æ¯æå–çš„JSON schema
        self.response_schema = self._create_financial_schema()
        self.llm = None
        
        if not GEMINI_AVAILABLE:
            logger.warning("âš ï¸ Geminiä¸å¯ç”¨: æ¨¡å—å¯¼å…¥å¤±è´¥")
        elif not use_gemini:
            logger.info("â„¹ï¸ ç”¨æˆ·é€‰æ‹©ä¸ä½¿ç”¨Gemini LLM")
        else:
            try:
                logger.info("ğŸš€ å°è¯•åˆå§‹åŒ–Gemini LLM...")
                self.llm = GeminiLLM(gemini_config)
                logger.info("âœ… Gemini LLMåˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logger.error(f"âŒ Gemini LLMåˆå§‹åŒ–å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                self.use_gemini = False
    
    def extract_key_info(self, transcription_text: str, video_title: str = "") -> Dict[str, Any]:
        """
        ä»è½¬å½•æ–‡æœ¬ä¸­æå–å…³é”®è´¢ç»ä¿¡æ¯
        
        Args:
            transcription_text: ASRè½¬å½•çš„æ–‡æœ¬
            video_title: è§†é¢‘æ ‡é¢˜
            
        Returns:
            åŒ…å«æå–ä¿¡æ¯çš„å­—å…¸
        """
        if not self.use_gemini:
            return self._extract_without_llm(transcription_text, video_title)
        
        # ä½¿ç”¨é‡è¯•æœºåˆ¶è¿›è¡Œæå–
        return self._extract_with_retry(transcription_text, video_title, max_attempts=3)
    
    def _extract_with_retry(self, transcription_text: str, video_title: str, max_attempts: int = 3) -> Dict[str, Any]:
        """
        å¸¦é‡è¯•çš„ä¿¡æ¯æå–
        
        Args:
            transcription_text: è½¬å½•æ–‡æœ¬
            video_title: è§†é¢‘æ ‡é¢˜  
            max_attempts: æœ€å¤§å°è¯•æ¬¡æ•°
            
        Returns:
            æå–çš„ä¿¡æ¯å­—å…¸
        """
        last_error = None
        
        for attempt in range(max_attempts):
            try:
                logger.info(f"ğŸ¤– å¼€å§‹ä½¿ç”¨Geminiæå–å…³é”®ä¿¡æ¯... (ç¬¬ {attempt + 1}/{max_attempts} æ¬¡)")
                
                # æ„å»ºæå–prompt
                prompt = self._build_extraction_prompt(transcription_text, video_title)
                
                # è°ƒç”¨LLM
                messages = [{"role": "user", "content": prompt}]
                
                response, tokens_used, finish_reason = self.llm.call(
                    message_list=messages,
                    temperature=0.1,
                    max_tokens=8000,
                    thinking_budget=8000,
                    response_mime_type="application/json",
                    response_schema=self.response_schema
                )
                
                logger.info(f"ğŸ’° LLMè°ƒç”¨å®Œæˆï¼Œä½¿ç”¨tokens: {tokens_used}")
                
                if finish_reason != "stop":
                    logger.warning(f"âš ï¸ LLMè°ƒç”¨æœªæ­£å¸¸ç»“æŸ: {finish_reason}")
                    # å¦‚æœä¸æ˜¯æ­£å¸¸ç»“æŸï¼Œä½†æœ‰å“åº”å†…å®¹ï¼Œä»ç„¶å°è¯•è§£æ
                    if not response.strip():
                        raise Exception(f"LLMè°ƒç”¨æœªæ­£å¸¸ç»“æŸä¸”å“åº”ä¸ºç©º: {finish_reason}")
                
                # è§£æJSONå“åº” - å¤šæ¬¡å°è¯•
                extracted_info = self._parse_json_response(response, attempt + 1)
                if extracted_info:
                    extracted_info["extraction_method"] = "gemini_llm"
                    extracted_info["tokens_used"] = tokens_used
                    extracted_info["attempts_used"] = attempt + 1
                    
                    logger.info(f"âœ… ä¿¡æ¯æå–æˆåŠŸ (ç¬¬ {attempt + 1} æ¬¡å°è¯•)")
                    return extracted_info
                else:
                    raise Exception("JSONè§£æå¤±è´¥")
                    
            except Exception as e:
                last_error = e
                logger.warning(f"âš ï¸ ç¬¬ {attempt + 1} æ¬¡æå–å¤±è´¥: {e}")
                
                if attempt < max_attempts - 1:
                    import time
                    wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿: 1, 2, 4ç§’
                    logger.info(f"ğŸ”„ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
        
        logger.error(f"âŒ æ‰€æœ‰æå–å°è¯•éƒ½å¤±è´¥äº†ï¼Œæœ€åé”™è¯¯: {last_error}")
        logger.info("ğŸ”„ å›é€€åˆ°åŸºç¡€è§„åˆ™æå–")
        return self._extract_without_llm(transcription_text, video_title)
    
    def _parse_json_response(self, response: str, attempt_num: int) -> Optional[Dict[str, Any]]:
        """
        è§£æJSONå“åº”ï¼Œæ”¯æŒå¤šç§æ ¼å¼æ¸…ç†
        
        Args:
            response: åŸå§‹å“åº”
            attempt_num: å°è¯•æ¬¡æ•°
            
        Returns:
            è§£æåçš„å­—å…¸æˆ–None
        """
        if not response.strip():
            logger.warning("å“åº”ä¸ºç©º")
            return None
        
        # å°è¯•å¤šç§æ–¹å¼æ¸…ç†å’Œè§£æJSON
        json_attempts = [
            response.strip(),  # åŸå§‹å“åº”
            response.strip().strip('```json').strip('```'),  # ç§»é™¤markdownä»£ç å—
            response[response.find('{'):response.rfind('}') + 1] if '{' in response and '}' in response else response,  # æå–JSONéƒ¨åˆ†
        ]
        
        for i, json_str in enumerate(json_attempts):
            try:
                if json_str.strip():
                    parsed = json.loads(json_str)
                    if i > 0:
                        logger.info(f"JSONè§£ææˆåŠŸ (ä½¿ç”¨ç¬¬ {i + 1} ç§æ¸…ç†æ–¹æ³•)")
                    return parsed
            except json.JSONDecodeError as e:
                if i == 0:
                    logger.debug(f"ç¬¬ {i + 1} ç§JSONè§£æå¤±è´¥: {e}")
                continue
        
        # è®°å½•å¤±è´¥è¯¦æƒ…
        logger.error(f"æ‰€æœ‰JSONè§£ææ–¹æ³•éƒ½å¤±è´¥äº†")
        logger.info(f"åŸå§‹å“åº” (å‰500å­—ç¬¦): {response[:500]}")
        return None
    
    def _create_financial_schema(self) -> Dict[str, Any]:
        """
        åˆ›å»ºè´¢ç»ä¿¡æ¯æå–çš„JSON schema
        
        Returns:
            å®Œæ•´çš„JSON schemaå®šä¹‰
        """
        return {
            "type": "object",
            "required": [
                "summary",
                "market_overview", 
                "macroeconomic_data",
                "stock_analysis",
                "key_events",
                "investment_advice",
                "risks_and_warnings"
            ],
            "properties": {
                "summary": {
                    "type": "string",
                    "description": "å¯¹æ•´ä¸ªè´¢ç»åˆ†æå†…å®¹çš„ç®€æ˜æ€»ç»“"
                },
                "market_overview": {
                    "type": "object",
                    "required": ["date", "major_indices", "market_sentiment"],
                    "properties": {
                        "date": {
                            "type": "string",
                            "description": "åˆ†ææ—¥æœŸï¼Œæ ¼å¼YYYY-MM-DD"
                        },
                        "major_indices": {
                            "type": "array",
                            "items": {
                                "type": "object",
                                "required": ["name", "performance"],
                                "properties": {
                                    "name": {
                                        "type": "string",
                                        "description": "æŒ‡æ•°åç§°ï¼Œå¦‚S&P 500, çº³æ–¯è¾¾å…‹ç­‰"
                                    },
                                    "performance": {
                                        "type": "string",
                                        "description": "å½“æ—¥è¡¨ç°æè¿°"
                                    },
                                    "current_level": {
                                        "type": "string",
                                        "description": "å½“å‰ç‚¹ä½æˆ–ä»·æ ¼"
                                    },
                                    "key_levels": {
                                        "type": "array",
                                        "items": {"type": "string"},
                                        "description": "å…³é”®æŠ€æœ¯ä½"
                                    },
                                    "analysis": {
                                        "type": "string",
                                        "description": "æŠ€æœ¯åˆ†æå’Œèµ°åŠ¿è§£è¯»"
                                    }
                                }
                            },
                            "description": "ä¸»è¦å¸‚åœºæŒ‡æ•°åˆ†æ"
                        },
                        "market_sentiment": {
                            "type": "string",
                            "description": "æ•´ä½“å¸‚åœºæƒ…ç»ªå’Œé©±åŠ¨å› ç´ "
                        }
                    }
                },
                "macroeconomic_data": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "required": ["indicator", "impact"],
                        "properties": {
                            "indicator": {
                                "type": "string",
                                "description": "å®è§‚ç»æµæŒ‡æ ‡åç§°"
                            },
                            "actual_value": {
                                "type": "string",
                                "description": "å®é™…å…¬å¸ƒå€¼"
                            },
                            "expected_value": {
                                "type": "string",
                                "description": "å¸‚åœºé¢„æœŸå€¼"
                            },
                            "previous_value": {
                                "type": "string",
                                "description": "å‰å€¼"
                            },
                            "impact": {
                                "type": "string",
                                "description": "å¯¹å¸‚åœºçš„å½±å“åˆ†æ"
                            },
                            "interpretation": {
                                "type": "string",
                                "description": "æ•°æ®è§£è¯»å’Œæ„ä¹‰"
                            }
                        }
                    },
                    "description": "å®è§‚ç»æµæ•°æ®å’Œåˆ†æ"
                },
                "stock_analysis": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "required": ["symbol", "key_points"],
                        "properties": {
                            "symbol": {
                                "type": "string",
                                "description": "è‚¡ç¥¨ä»£ç æˆ–ETFä»£ç "
                            },
                            "company_name": {
                                "type": "string",
                                "description": "å…¬å¸æˆ–äº§å“å…¨å"
                            },
                            "current_price": {
                                "type": "string",
                                "description": "å½“å‰ä»·æ ¼æˆ–ä»·æ ¼åŒºé—´"
                            },
                            "price_change": {
                                "type": "string",
                                "description": "ä»·æ ¼å˜åŒ–"
                            },
                            "key_points": {
                                "type": "array",
                                "items": {"type": "string"},
                                "description": "å…³é”®åˆ†æè¦ç‚¹"
                            },
                            "price_levels": {
                                "type": "object",
                                "properties": {
                                    "support": {
                                        "type": "array",
                                        "items": {"type": "string"},
                                        "description": "æ”¯æ’‘ä½"
                                    },
                                    "resistance": {
                                        "type": "array",
                                        "items": {"type": "string"},
                                        "description": "é˜»åŠ›ä½"
                                    },
                                    "target": {
                                        "type": "array", 
                                        "items": {"type": "string"},
                                        "description": "ç›®æ ‡ä½"
                                    }
                                }
                            },
                            "recommendation": {
                                "type": "string",
                                "enum": ["ä¹°å…¥", "æŒæœ‰", "å–å‡º", "è§‚æœ›"],
                                "description": "æŠ•èµ„å»ºè®®"
                            },
                            "risk_reward_ratio": {
                                "type": "string",
                                "description": "é£é™©æ”¶ç›Šæ¯”"
                            },
                            "analyst_notes": {
                                "type": "string",
                                "description": "åˆ†æå¸ˆå¤‡æ³¨"
                            }
                        }
                    },
                    "description": "ä¸ªè‚¡åˆ†æ"
                },
                "key_events": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "required": ["event", "impact"],
                        "properties": {
                            "event": {
                                "type": "string",
                                "description": "å…³é”®äº‹ä»¶æè¿°"
                            },
                            "date": {
                                "type": "string",
                                "description": "äº‹ä»¶æ—¥æœŸ"
                            },
                            "impact": {
                                "type": "string",
                                "description": "å¯¹å¸‚åœºçš„å½±å“"
                            },
                            "category": {
                                "type": "string",
                                "enum": ["è´¢æŠ¥", "æ”¿ç­–", "ç»æµæ•°æ®", "ä¼ä¸šè¡Œä¸º", "å…¶ä»–"],
                                "description": "äº‹ä»¶ç±»åˆ«"
                            }
                        }
                    },
                    "description": "å½±å“å¸‚åœºçš„å…³é”®äº‹ä»¶"
                },
                "investment_advice": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "required": ["advice", "timeframe"],
                        "properties": {
                            "advice": {
                                "type": "string",
                                "description": "å…·ä½“æŠ•èµ„å»ºè®®"
                            },
                            "timeframe": {
                                "type": "string",
                                "enum": ["çŸ­æœŸ", "ä¸­æœŸ", "é•¿æœŸ"],
                                "description": "å»ºè®®çš„æ—¶é—´æ¡†æ¶"
                            },
                            "rationale": {
                                "type": "string",
                                "description": "å»ºè®®çš„ç†ç”±"
                            },
                            "target_audience": {
                                "type": "string",
                                "description": "ç›®æ ‡æŠ•èµ„è€…ç±»å‹"
                            }
                        }
                    },
                    "description": "æŠ•èµ„å»ºè®®"
                },
                "risks_and_warnings": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "required": ["risk", "severity"],
                        "properties": {
                            "risk": {
                                "type": "string",
                                "description": "é£é™©æè¿°"
                            },
                            "severity": {
                                "type": "string",
                                "enum": ["ä½", "ä¸­", "é«˜"],
                                "description": "é£é™©ä¸¥é‡ç¨‹åº¦"
                            },
                            "probability": {
                                "type": "string",
                                "enum": ["ä½", "ä¸­", "é«˜"],
                                "description": "é£é™©å‘ç”Ÿæ¦‚ç‡"
                            },
                            "mitigation": {
                                "type": "string",
                                "description": "é£é™©ç¼“è§£æªæ–½"
                            }
                        }
                    },
                    "description": "é£é™©æç¤ºå’Œè­¦å‘Š"
                }
            }
        }
    
    def _build_extraction_prompt(self, text: str, title: str) -> str:
        """æ„å»ºä¿¡æ¯æå–çš„prompt"""
        # å°è¯•ä»promptsç›®å½•è¯»å–æ¨¡æ¿
        prompt_file = Path(__file__).parent.parent / "prompts" / "financial_extraction_prompt.txt"
        
        if prompt_file.exists():
            try:
                with open(prompt_file, 'r', encoding='utf-8') as f:
                    prompt_template = f.read()
                # æ›¿æ¢æ¨¡æ¿ä¸­çš„å ä½ç¬¦
                prompt = prompt_template.format(title=title, text=text)
                logger.info(f"âœ… ä½¿ç”¨å¤–éƒ¨promptæ¨¡æ¿: {prompt_file}")
                return prompt
            except Exception as e:
                raise RuntimeError(f"âš ï¸ è¯»å–promptæ¨¡æ¿å¤±è´¥, prompt_file: {prompt_file}, error: {e}")
    
    def _extract_without_llm(self, text: str, title: str) -> Dict[str, Any]:
        """ä¸ä½¿ç”¨LLMçš„åŸºç¡€ä¿¡æ¯æå–"""
        logger.info("ğŸ“ ä½¿ç”¨åŸºç¡€æ–¹æ³•æå–ä¿¡æ¯...")
        
        # ç®€å•çš„å…³é”®è¯æå–
        stocks_mentioned = self._extract_stock_symbols(text)
        numbers = self._extract_numbers(text)
        
        return {
            "extraction_method": "basic_rules",
            "summary": f"åŸºäºè§†é¢‘æ ‡é¢˜çš„è´¢ç»åˆ†æå†…å®¹: {title}",
            "text_length": len(text),
            "stocks_mentioned": stocks_mentioned,
            "numbers_found": numbers[:10],  # é™åˆ¶æ•°é‡
            "market_overview": {
                "date": "",
                "major_indices": [],
                "market_sentiment": ""
            },
            "macroeconomic_data": [],
            "stock_analysis": [],
            "key_events": [],
            "investment_advice": [],
            "risks_and_warnings": [],
            "note": "ä½¿ç”¨åŸºç¡€è§„åˆ™æå–ï¼Œä¿¡æ¯æœ‰é™ã€‚å»ºè®®é…ç½®Gemini LLMè·å¾—æ›´è¯¦ç»†çš„åˆ†æã€‚"
        }
    
    def _extract_stock_symbols(self, text: str) -> List[str]:
        """æå–è‚¡ç¥¨ä»£ç """
        import re
        
        # å¸¸è§ç¾è‚¡ä»£ç æ¨¡å¼
        patterns = [
            r'\b([A-Z]{1,5})\b',  # 1-5ä¸ªå¤§å†™å­—æ¯çš„è‚¡ç¥¨ä»£ç 
            r'ç‰¹æ–¯æ‹‰|TSLA',
            r'è‹¹æœ|AAPL', 
            r'è°·æ­Œ|GOOGL|GOOG',
            r'å¾®è½¯|MSFT',
            r'äºšé©¬é€Š|AMZN',
            r'è‹±ä¼Ÿè¾¾|NVDA',
            r'Meta|META',
            r'åšé€š|AVGO',
            r'LULU'
        ]
        
        stocks = set()
        for pattern in patterns:
            matches = re.findall(pattern, text)
            stocks.update(matches)
        
        # è¿‡æ»¤æ‰å¸¸è§çš„éè‚¡ç¥¨è¯æ±‡
        exclude = {'AND', 'THE', 'FOR', 'ARE', 'YOU', 'ALL', 'BUT', 'NOT', 'CAN', 'HAD', 'HER', 'WAS', 'ONE', 'OUR', 'OUT', 'DAY', 'GET', 'HAS', 'HIM', 'HIS', 'HOW', 'ITS', 'NEW', 'NOW', 'OLD', 'SEE', 'TWO', 'WHO', 'BOY', 'DID', 'DOWN', 'EACH', 'FEW', 'FROM', 'HAVE', 'HERE', 'INTO', 'JUST', 'LIKE', 'LONG', 'MADE', 'MANY', 'OVER', 'SUCH', 'TAKE', 'THAN', 'THEM', 'WELL', 'WERE', 'WHAT', 'WITH', 'WORK'}
        stocks = [s for s in stocks if s not in exclude and len(s) <= 5]
        
        return list(stocks)[:10]  # é™åˆ¶è¿”å›æ•°é‡
    
    def _extract_numbers(self, text: str) -> List[str]:
        """æå–å¯èƒ½çš„ä»·æ ¼å’Œç™¾åˆ†æ¯”æ•°æ®"""
        import re
        
        patterns = [
            r'\b\d+\.?\d*%',  # ç™¾åˆ†æ¯”
            r'\$\d+\.?\d*',   # ä»·æ ¼
            r'\b\d{1,4}\.?\d*å—',  # ä¸­æ–‡ä»·æ ¼æè¿°
            r'\b\d+\.?\d*ç¾å…ƒ',    # ç¾å…ƒ
            r'\b\d+\.?\d*äº¿',      # äº¿
        ]
        
        numbers = []
        for pattern in patterns:
            matches = re.findall(pattern, text)
            numbers.extend(matches)
        
        return numbers
    
    def save_extracted_info(self, info: Dict[str, Any], output_path: str) -> bool:
        """
        ä¿å­˜æå–çš„ä¿¡æ¯åˆ°JSONæ–‡ä»¶
        
        Args:
            info: æå–çš„ä¿¡æ¯å­—å…¸
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            output_file = Path(output_path)
            output_file.parent.mkdir(parents=True, exist_ok=True)
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(info, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ğŸ’¾ æå–ä¿¡æ¯å·²ä¿å­˜åˆ°: {output_file}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜ä¿¡æ¯å¤±è´¥: {e}")
            return False


def extract_financial_info(transcription_text: str, 
                         video_title: str = "", 
                         output_path: Optional[str] = None) -> Dict[str, Any]:
    """
    ä¾¿æ·å‡½æ•°ï¼šæå–è´¢ç»ä¿¡æ¯
    
    Args:
        transcription_text: è½¬å½•æ–‡æœ¬
        video_title: è§†é¢‘æ ‡é¢˜
        output_path: å¯é€‰çš„è¾“å‡ºæ–‡ä»¶è·¯å¾„
        
    Returns:
        æå–çš„ä¿¡æ¯å­—å…¸
    """
    extractor = FinancialInfoExtractor()
    info = extractor.extract_key_info(transcription_text, video_title)
    
    if output_path:
        extractor.save_extracted_info(info, output_path)
    
    return info


def test_with_real_transcription():
    """ä½¿ç”¨çœŸå®çš„è½¬å½•æ–‡æœ¬æµ‹è¯•LLMä¿¡æ¯æå–åŠŸèƒ½"""
    # è¯»å–çœŸå®çš„è½¬å½•æ–‡æœ¬
    transcription_file = Path(__file__).parent.parent / "downloads" / "rhino_finance" / "2025-09-10" / "transcription" / "rhino_ZKo41ja8rD0.txt"
    
    if not transcription_file.exists():
        print(f"âŒ è½¬å½•æ–‡ä»¶ä¸å­˜åœ¨: {transcription_file}")
        return
    
    try:
        with open(transcription_file, 'r', encoding='utf-8') as f:
            real_transcription = f.read()
        
        print("ğŸ§ª ä½¿ç”¨çœŸå®è½¬å½•æ–‡æœ¬æµ‹è¯•LLMä¿¡æ¯æå–åŠŸèƒ½...")
        print(f"ğŸ“„ è½¬å½•æ–‡æœ¬é•¿åº¦: {len(real_transcription)} å­—ç¬¦")
        print("="*60)
        
        # æå–ä¿¡æ¯
        extractor = FinancialInfoExtractor()
        result = extractor.extract_key_info(
            transcription_text=real_transcription,
            video_title="ç¾è‚¡ NVDAè·å¾—éƒ¨åˆ†H20è®¸å¯ï¼APPã€HOODæ›´æ–°ï¼Œè¿›æ ‡æ™®500ï¼MSTRå†è½é€‰ï¼ŒæŠ€æœ¯é£é™©ï¼UNHä¸´é—¨ä¸€è„šï¼"
        )
        
        # ä¿å­˜ç»“æœ
        output_file = Path(__file__).parent.parent / "downloads" / "rhino_finance" / "2025-09-10" / "analysis" / "rhino_ZKo41ja8rD0_analysis2.json"
        extractor.save_extracted_info(result, str(output_file))
        
        # æ˜¾ç¤ºæå–ç»“æœæ‘˜è¦
        print("âœ… ä¿¡æ¯æå–å®Œæˆ!")
        print("="*60)
        
        print(f"ğŸ¤– æå–æ–¹æ³•: {result.get('extraction_method', 'unknown')}")
        
        if result.get('summary'):
            print(f"ğŸ“‹ å†…å®¹æ‘˜è¦: {result['summary']}")
        
        # æ˜¾ç¤ºå¸‚åœºæ¦‚å†µ
        market_overview = result.get('market_overview', {})
        if market_overview.get('major_indices'):
            print(f"\nğŸ“ˆ ä¸»è¦æŒ‡æ•°:")
            for index in market_overview['major_indices'][:3]:  # æ˜¾ç¤ºå‰3ä¸ª
                print(f"  â€¢ {index.get('name', 'N/A')}: {index.get('performance', 'N/A')}")
        
        # æ˜¾ç¤ºå®è§‚æ•°æ®
        macro_data = result.get('macroeconomic_data', [])
        if macro_data:
            print(f"\nğŸŒ å®è§‚ç»æµæ•°æ® ({len(macro_data)}æ¡):")
            for data in macro_data[:3]:  # æ˜¾ç¤ºå‰3æ¡
                print(f"  â€¢ {data.get('indicator', 'N/A')}: {data.get('value', 'N/A')}")
        
        # æ˜¾ç¤ºè‚¡ç¥¨åˆ†æ
        stock_analysis = result.get('stock_analysis', [])
        if stock_analysis:
            print(f"\nğŸ“Š ä¸ªè‚¡åˆ†æ ({len(stock_analysis)}åªè‚¡ç¥¨):")
            for stock in stock_analysis:
                symbol = stock.get('symbol', 'N/A')
                company = stock.get('company_name', 'N/A')
                outlook = stock.get('outlook', 'N/A')
                print(f"  ğŸ¢ {symbol} ({company})")
                print(f"     è§‚ç‚¹: {outlook}")
                
                # æ˜¾ç¤ºå…³é”®ç‚¹ä½
                price_levels = stock.get('price_levels', {})
                if price_levels.get('support'):
                    print(f"     æ”¯æ’‘ä½: {', '.join(price_levels['support'])}")
                if price_levels.get('resistance'):
                    print(f"     é˜»åŠ›ä½: {', '.join(price_levels['resistance'])}")
        
        # æ˜¾ç¤ºæŠ•èµ„å»ºè®®
        advice = result.get('investment_advice', [])
        if advice:
            print(f"\nğŸ’¡ æŠ•èµ„å»ºè®® ({len(advice)}æ¡):")
            for item in advice[:3]:  # æ˜¾ç¤ºå‰3æ¡
                print(f"  â€¢ {item}")
        
        # æ˜¾ç¤ºé£é™©è­¦ç¤º
        risks = result.get('risks_and_warnings', [])
        if risks:
            print(f"\nâš ï¸ é£é™©æç¤º ({len(risks)}æ¡):")
            for risk in risks[:2]:  # æ˜¾ç¤ºå‰2æ¡
                print(f"  â€¢ {risk}")
        
        print("="*60)
        print(f"ğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
        # æ˜¾ç¤ºtokensä½¿ç”¨æƒ…å†µ
        if result.get('tokens_used'):
            print(f"ğŸ’° LLM Tokens ä½¿ç”¨é‡: {result['tokens_used']}")
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # ä½¿ç”¨çœŸå®è½¬å½•æ–‡æœ¬æµ‹è¯•
    test_with_real_transcription()
