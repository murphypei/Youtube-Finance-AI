"""
è´¢ç»åˆ†æç»“æœæ±‡æ€»å’Œèšåˆå¤„ç†æ¨¡å—
å¯¹æ‰¹é‡å¤„ç†çš„ç»“æœè¿›è¡Œæ—¥æœŸèšåˆã€è‚¡ç¥¨ä¿¡æ¯æ•´ç†å’Œå®è§‚æ•°æ®æ±‡æ€»
"""

import json
import os
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from collections import defaultdict
import re

class FinancialAnalyzer:
    """è´¢ç»åˆ†æç»“æœå¤„ç†å™¨"""
    
    def __init__(self, data_dir: str = None):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            data_dir: æ•°æ®ç›®å½•è·¯å¾„ï¼Œé»˜è®¤ä¸ºdownloads/rhino_finance
        """
        if data_dir is None:
            self.data_dir = Path.cwd() / "downloads" / "rhino_finance"
        else:
            self.data_dir = Path(data_dir)
        
        print(f"ğŸ“Š åˆå§‹åŒ–è´¢ç»åˆ†æå™¨")
        print(f"ğŸ“ æ•°æ®ç›®å½•: {self.data_dir}")
    
    def load_batch_results(self, results_file: str = None) -> Dict[str, Any]:
        """
        åŠ è½½æ‰¹é‡å¤„ç†ç»“æœæ–‡ä»¶
        
        Args:
            results_file: ç»“æœæ–‡ä»¶è·¯å¾„ï¼Œä¸ºNoneæ—¶åŠ è½½æœ€æ–°çš„ç»“æœæ–‡ä»¶
            
        Returns:
            æ‰¹é‡å¤„ç†ç»“æœæ•°æ®
        """
        if results_file is None:
            # æŸ¥æ‰¾æœ€æ–°çš„æ‰¹é‡ç»“æœæ–‡ä»¶
            batch_files = list(self.data_dir.glob("batch_results_*.json"))
            if not batch_files:
                raise FileNotFoundError("æœªæ‰¾åˆ°æ‰¹é‡å¤„ç†ç»“æœæ–‡ä»¶")
            
            # æŒ‰æ—¶é—´æ’åºï¼Œè·å–æœ€æ–°çš„
            batch_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
            results_file = batch_files[0]
            print(f"ğŸ“„ åŠ è½½æœ€æ–°æ‰¹é‡ç»“æœ: {results_file.name}")
        else:
            results_file = Path(results_file)
        
        with open(results_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def collect_all_analysis_data(self) -> List[Dict[str, Any]]:
        """
        æ”¶é›†æ‰€æœ‰æ—¥æœŸç›®å½•ä¸‹çš„åˆ†æç»“æœ
        
        Returns:
            æ‰€æœ‰åˆ†æç»“æœçš„åˆ—è¡¨
        """
        print("ğŸ” æ”¶é›†æ‰€æœ‰åˆ†ææ•°æ®...")
        
        all_data = []
        
        # éå†æ‰€æœ‰æ—¥æœŸç›®å½•
        for date_dir in self.data_dir.iterdir():
            if not date_dir.is_dir() or not re.match(r'\d{4}-\d{2}-\d{2}', date_dir.name):
                continue
            
            analysis_dir = date_dir / 'analysis'
            if not analysis_dir.exists():
                continue
            
            print(f"ğŸ“… å¤„ç†æ—¥æœŸ: {date_dir.name}")
            
            # åŠ è½½è¯¥æ—¥æœŸçš„æ‰€æœ‰åˆ†ææ–‡ä»¶
            for analysis_file in analysis_dir.glob("*.json"):
                try:
                    with open(analysis_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        
                    # æ·»åŠ å…ƒæ•°æ®
                    data['file_date'] = date_dir.name
                    data['file_name'] = analysis_file.name
                    data['file_path'] = str(analysis_file)
                    
                    all_data.append(data)
                    
                except Exception as e:
                    print(f"âš ï¸ è¯»å– {analysis_file} å¤±è´¥: {e}")
        
        print(f"âœ… æ”¶é›†åˆ° {len(all_data)} ä»½åˆ†ææ•°æ®")
        return all_data
    
    def aggregate_by_date(self, analysis_data: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
        """
        æŒ‰æ—¥æœŸèšåˆåˆ†ææ•°æ®
        
        Args:
            analysis_data: åˆ†ææ•°æ®åˆ—è¡¨
            
        Returns:
            æŒ‰æ—¥æœŸèšåˆçš„æ•°æ®å­—å…¸
        """
        print("ğŸ“Š æŒ‰æ—¥æœŸèšåˆæ•°æ®...")
        
        date_groups = defaultdict(list)
        
        for data in analysis_data:
            file_date = data.get('file_date', 'unknown')
            date_groups[file_date].append(data)
        
        # æŒ‰æ—¥æœŸæ’åº
        sorted_dates = dict(sorted(date_groups.items(), reverse=True))
        
        for date, items in sorted_dates.items():
            print(f"ğŸ“… {date}: {len(items)} ä»½åˆ†æ")
        
        return sorted_dates
    
    def extract_macro_news(self, date_groups: Dict[str, List[Dict[str, Any]]], days: int = 1) -> List[Dict[str, Any]]:
        """
        æå–æœ€è¿‘å‡ å¤©çš„å®è§‚æ–°é—»
        
        Args:
            date_groups: æŒ‰æ—¥æœŸåˆ†ç»„çš„æ•°æ®
            days: æå–å¤©æ•°
            
        Returns:
            å®è§‚æ–°é—»åˆ—è¡¨
        """
        print(f"ğŸ“° æå–æœ€è¿‘ {days} å¤©çš„å®è§‚æ–°é—»...")
        
        macro_news = []
        processed_dates = 0
        
        for date, items in date_groups.items():
            if processed_dates >= days:
                break
                
            for item in items:
                # æå–å®è§‚ç»æµæ•°æ®
                macro_data = item.get('macroeconomic_data', [])
                if macro_data:
                    for data_point in macro_data:
                        macro_news.append({
                            'date': date,
                            'source_file': item.get('file_name', ''),
                            'indicator': data_point.get('indicator', ''),
                            'value': data_point.get('actual_value', data_point.get('value', '')),
                            'expected': data_point.get('expected_value', data_point.get('expected', '')),
                            'impact': data_point.get('impact', ''),
                            'description': data_point.get('interpretation', data_point.get('description', ''))
                        })
                
                # æå–å…³é”®äº‹ä»¶
                key_events = item.get('key_events', [])
                if key_events:
                    for event in key_events:
                        # å¦‚æœeventæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦‚æœæ˜¯å­—å…¸ï¼Œæå–ç›¸å…³å­—æ®µ
                        if isinstance(event, str):
                            event_desc = event
                            event_impact = ''
                        elif isinstance(event, dict):
                            event_desc = event.get('description', event.get('event', str(event)))
                            event_impact = event.get('impact', '')
                        else:
                            event_desc = str(event)
                            event_impact = ''
                            
                        macro_news.append({
                            'date': date,
                            'source_file': item.get('file_name', ''),
                            'indicator': 'é‡è¦äº‹ä»¶',
                            'value': event_desc,
                            'expected': '',
                            'impact': event_impact,
                            'description': event_desc
                        })
            
            processed_dates += 1
        
        print(f"âœ… æå–åˆ° {len(macro_news)} æ¡å®è§‚ä¿¡æ¯")
        return macro_news
    
    def extract_stock_positions(self, date_groups: Dict[str, List[Dict[str, Any]]], days: int = 7) -> List[Dict[str, Any]]:
        """
        æå–æœ€è¿‘å‡ å¤©çš„è‚¡ç¥¨ç‚¹ä½ä¿¡æ¯
        
        Args:
            date_groups: æŒ‰æ—¥æœŸåˆ†ç»„çš„æ•°æ®
            days: æå–å¤©æ•°
            
        Returns:
            è‚¡ç¥¨ç‚¹ä½ä¿¡æ¯åˆ—è¡¨
        """
        print(f"ğŸ“ˆ æå–æœ€è¿‘ {days} å¤©çš„è‚¡ç¥¨ç‚¹ä½ä¿¡æ¯...")
        
        stock_positions = []
        stock_summary = defaultdict(list)  # æŒ‰è‚¡ç¥¨ä»£ç æ±‡æ€»
        processed_dates = 0
        
        for date, items in date_groups.items():
            if processed_dates >= days:
                break
                
            for item in items:
                stock_analysis = item.get('stock_analysis', [])
                
                for stock in stock_analysis:
                    symbol = stock.get('symbol', '')
                    company_name = stock.get('company_name', '')
                    
                    # æå–ä»·æ ¼ä¿¡æ¯
                    current_price = stock.get('current_price', '')
                    price_levels = stock.get('price_levels', {})
                    
                    # æ”¯æ’‘é˜»åŠ›ä½å¯èƒ½åœ¨ä¸åŒå­—æ®µä¸­
                    support_levels = (price_levels.get('support', []) or 
                                    price_levels.get('support_levels', []) or
                                    [])
                    resistance_levels = (price_levels.get('resistance', []) or 
                                       price_levels.get('resistance_levels', []) or
                                       [])
                    
                    # æå–æ“ä½œå»ºè®® - å°è¯•å¤šä¸ªå¯èƒ½çš„å­—æ®µ
                    outlook = stock.get('outlook', '')
                    recommendation = stock.get('recommendation', '')
                    analyst_notes = stock.get('analyst_notes', '')
                    
                    # æ¨æ–­æ“ä½œç±»å‹ - ç»¼åˆå¤šä¸ªå­—æ®µ
                    action = self._determine_action(outlook, recommendation + " " + analyst_notes)
                    
                    position_info = {
                        'date': date,
                        'source_file': item.get('file_name', ''),
                        'symbol': symbol,
                        'company_name': company_name,
                        'current_price': current_price,
                        'support_levels': support_levels,
                        'resistance_levels': resistance_levels,
                        'action': action,
                        'outlook': outlook,
                        'recommendation': recommendation,
                        'key_points': stock.get('key_points', []),
                        'risk_factors': stock.get('risk_factors', [])
                    }
                    
                    stock_positions.append(position_info)
                    stock_summary[symbol].append(position_info)
            
            processed_dates += 1
        
        print(f"âœ… æå–åˆ° {len(stock_positions)} æ¡è‚¡ç¥¨ç‚¹ä½ä¿¡æ¯")
        print(f"ğŸ“Š æ¶‰åŠ {len(stock_summary)} åªä¸åŒè‚¡ç¥¨")
        
        return stock_positions
    
    def _determine_action(self, outlook: str, recommendation: str) -> str:
        """
        æ ¹æ®å±•æœ›å’Œå»ºè®®åˆ¤æ–­æ“ä½œç±»å‹
        
        Args:
            outlook: å±•æœ›æè¿°
            recommendation: å»ºè®®æè¿°
            
        Returns:
            æ“ä½œç±»å‹: ä¹°å…¥/å–å‡º/æŒæœ‰/è§‚æœ›
        """
        text = (str(outlook) + " " + str(recommendation)).lower()
        
        # ä¹°å…¥ä¿¡å·å…³é”®è¯ - æ›´å…¨é¢çš„å…³é”®è¯
        buy_keywords = [
            'ä¹°å…¥', 'å»ºè®®ä¹°å…¥', 'é€¢ä½ä¹°å…¥', 'å¢æŒ', 'å»ºè®®å¢æŒ', 'buy', 'long', 
            'çœ‹å¥½', 'å»ºè®®å…³æ³¨', 'åŠ ä»“', 'å»ºè®®åŠ ä»“', 'ç§¯æ', 'å¼ºçƒˆæ¨è', 
            'ä¸Šæ¶¨', 'çœ‹æ¶¨', 'å»ºè®®æŒæœ‰å¹¶é€‚åº¦åŠ ä»“', 'å¼ºåŠ¿', 'é‡å›ä¸Šæ”»'
        ]
        
        # å–å‡ºä¿¡å·å…³é”®è¯  
        sell_keywords = [
            'å–å‡º', 'å»ºè®®å–å‡º', 'å‡æŒ', 'å»ºè®®å‡æŒ', 'sell', 'short', 
            'çœ‹ç©º', 'è°¨æ…', 'å‡ä»“', 'ä¸å»ºè®®', 'è¶…ä¹°', 'ä¸å®œè¿½é«˜',
            'è·åˆ©äº†ç»“', 'æ­¢ç›ˆ', 'è§„é¿é£é™©', 'ç ´ä½ä¸‹è¡Œ'
        ]
        
        # æŒæœ‰ä¿¡å·å…³é”®è¯
        hold_keywords = [
            'æŒæœ‰', 'ç»´æŒ', 'hold', 'é•¿çº¿æŒæœ‰', 'ä¿æŒ', 'ç»§ç»­æŒæœ‰',
            'ç¨³å¥', 'ç»´æŒä»“ä½', 'ä¸å˜', 'æ³¢æ®µ'
        ]
        
        # è§‚æœ›ä¿¡å·å…³é”®è¯
        watch_keywords = [
            'è§‚æœ›', 'ç­‰å¾…', 'æš‚æ—¶è§‚æœ›', 'è°¨æ…è§‚æœ›', 'é™è§‚å…¶å˜', 
            'ç­‰å¾…æ—¶æœº', 'æš‚ä¸æ“ä½œ', 'å…³æ³¨', 'è·Ÿè¸ª'
        ]
        
        # æŒ‰ä¼˜å…ˆçº§åŒ¹é…
        for keyword in buy_keywords:
            if keyword in text:
                return 'ä¹°å…¥'
        
        for keyword in sell_keywords:
            if keyword in text:
                return 'å–å‡º'
        
        for keyword in hold_keywords:
            if keyword in text:
                return 'æŒæœ‰'
                
        for keyword in watch_keywords:
            if keyword in text:
                return 'è§‚æœ›'
        
        return 'è§‚æœ›'  # é»˜è®¤
    
    def create_summary_report(self, macro_news: List[Dict[str, Any]], stock_positions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        åˆ›å»ºæ±‡æ€»æŠ¥å‘Š
        
        Args:
            macro_news: å®è§‚æ–°é—»åˆ—è¡¨
            stock_positions: è‚¡ç¥¨ç‚¹ä½åˆ—è¡¨
            
        Returns:
            æ±‡æ€»æŠ¥å‘Šæ•°æ®
        """
        print("ğŸ“‹ åˆ›å»ºæ±‡æ€»æŠ¥å‘Š...")
        
        # ç»Ÿè®¡è‚¡ç¥¨æ“ä½œåˆ†å¸ƒ
        action_counts = defaultdict(int)
        for pos in stock_positions:
            action_counts[pos['action']] += 1
        
        # è·å–æœ€æ´»è·ƒçš„è‚¡ç¥¨
        symbol_counts = defaultdict(int)
        for pos in stock_positions:
            if pos['symbol']:
                symbol_counts[pos['symbol']] += 1
        
        most_mentioned = dict(sorted(symbol_counts.items(), key=lambda x: x[1], reverse=True)[:10])
        
        summary = {
            'generated_at': datetime.now().isoformat(),
            'macro_news_count': len(macro_news),
            'stock_positions_count': len(stock_positions),
            'action_distribution': dict(action_counts),
            'most_mentioned_stocks': most_mentioned,
            'latest_macro_news': macro_news[:5],  # æœ€æ–°5æ¡
            'active_stock_positions': stock_positions[:10],  # æœ€æ´»è·ƒ10åª
            'macro_news': macro_news,
            'stock_positions': stock_positions
        }
        
        print(f"âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        print(f"ğŸ“° å®è§‚æ–°é—»: {len(macro_news)} æ¡")
        print(f"ğŸ“ˆ è‚¡ç¥¨ç‚¹ä½: {len(stock_positions)} æ¡")
        print(f"ğŸ¯ æ“ä½œåˆ†å¸ƒ: {dict(action_counts)}")
        
        return summary
    
    def save_summary_report(self, summary: Dict[str, Any], filename: str = None) -> str:
        """
        ä¿å­˜æ±‡æ€»æŠ¥å‘Š
        
        Args:
            summary: æ±‡æ€»æŠ¥å‘Šæ•°æ®
            filename: æ–‡ä»¶åï¼Œä¸ºNoneæ—¶è‡ªåŠ¨ç”Ÿæˆ
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"summary_report_{timestamp}.json"
        
        output_file = self.data_dir / filename
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ æ±‡æ€»æŠ¥å‘Šå·²ä¿å­˜: {output_file}")
        return str(output_file)


def main():
    """ä¸»å‡½æ•°ï¼Œç”Ÿæˆåˆ†ææ±‡æ€»æŠ¥å‘Š"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ğŸ“Š è´¢ç»åˆ†æç»“æœæ±‡æ€»å·¥å…·")
    parser.add_argument('--data-dir', help='æ•°æ®ç›®å½•è·¯å¾„')
    parser.add_argument('--macro-days', type=int, default=1, help='å®è§‚æ–°é—»æå–å¤©æ•° (é»˜è®¤: 1)')
    parser.add_argument('--stock-days', type=int, default=7, help='è‚¡ç¥¨ç‚¹ä½æå–å¤©æ•° (é»˜è®¤: 7)')
    
    args = parser.parse_args()
    
    print("ğŸ“Š è´¢ç»åˆ†æç»“æœæ±‡æ€»å·¥å…·")
    print("=" * 40)
    
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = FinancialAnalyzer(args.data_dir)
    
    # æ”¶é›†åˆ†ææ•°æ®
    analysis_data = analyzer.collect_all_analysis_data()
    if not analysis_data:
        print("âŒ æœªæ‰¾åˆ°åˆ†ææ•°æ®")
        return
    
    # æŒ‰æ—¥æœŸèšåˆ
    date_groups = analyzer.aggregate_by_date(analysis_data)
    
    # æå–å®è§‚æ–°é—»å’Œè‚¡ç¥¨ç‚¹ä½
    macro_news = analyzer.extract_macro_news(date_groups, args.macro_days)
    stock_positions = analyzer.extract_stock_positions(date_groups, args.stock_days)
    
    # åˆ›å»ºæ±‡æ€»æŠ¥å‘Š
    summary = analyzer.create_summary_report(macro_news, stock_positions)
    
    # ä¿å­˜æŠ¥å‘Š
    report_file = analyzer.save_summary_report(summary)
    
    print(f"\nğŸ‰ æ±‡æ€»å®Œæˆ!")
    print(f"ğŸ“„ æŠ¥å‘Šæ–‡ä»¶: {report_file}")


if __name__ == "__main__":
    main()
